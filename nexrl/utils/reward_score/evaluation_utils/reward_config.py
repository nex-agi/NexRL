# Copyright (c) Nex-AGI. All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
This module defines data structures and base classes for reward calculations
to evaluate model responses for various problem types, including math and coding.
"""

from dataclasses import dataclass, field
from typing import Any

# from enum import Enum


@dataclass
class RewardConfig:
    # Use LLM as ORM to evaluate correctness.
    use_math_orm: bool = False

    # General reward constants.
    correct_reward: float = 1.0
    # incorrect_reward: float = -1.0
    incorrect_reward: float = 0
    format_reward: float = 0.1
    format_error_reward: float = 0
    # unk_error_reward: float = -1.0
    unk_error_reward: float = 0
    llm_correct_reward: float = 0.7


# class RewardType(Enum):
#     """
#     Enum class representing the different types of rewards that can be assigned.

#     Attributes:
#         MATH (str): Represents a math-related problem type.
#         CODE (str): Represents a coding-related problem type.
#         UNK (str): Represents an unknown or unclassified problem type.
#     """
#     MATH = 'MATH'
#     CODE = 'CODE'
#     UNK = 'UNK'


# @dataclass
# class RewardInput:
#     """Data structure for input required to calculate rewards.

#     Attributes:
#         problem (str): The original problem text or prompt provided to the model.
#         model_response (str): The response generated by the model that needs evaluation.
#         ground_truth (str): Additional contextual information necessary for evaluation:
#             - For math problems: This may include the ground truth answer.
#     """
#     problem: str
#     model_response: str
#     ground_truth: str


# @dataclass
# class RewardOutput:
#     """Data structure for the output of reward calculations.

#     Attributes:
#         reward (float): The computed reward value based on the evaluation of the model's response.
#         is_correct (bool): A boolean flag indicating whether the model's response is deemed correct.
#     """
#     reward: float
#     is_correct: bool


class RewardFn:
    """Abstract base class for defining reward calculation strategies.

    This class should be subclassed to implement specific reward calculation logic.
    The __call__ method must be overridden to provide the functionality for evaluating
    the input and returning the corresponding reward output.
    """

    def __init__(self, config: RewardConfig):
        self.config = config

    def __call__(
        self,
        prompt: str,
        model_response: str,
        ground_truth: str | list[str],
        raw_prompt: list[dict[str, Any]] | None = None,
    ):
        raise NotImplementedError("Subclasses must implement this method.")
